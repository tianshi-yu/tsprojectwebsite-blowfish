[{"content":" Journal # T. Yu, Z. Wang, F. Nelli, Y. Tan, G. Ducrozet, and A. Toffoli, \u0026ldquo;Assessing the ship motion prediction capabilities of the open-source model NEMOH against field observations\u0026rdquo;, Ocean Engineering, vol. 344, 123580, 2026.\nZ. Su, T. Yu, A. Polyvyanyy, Y. Tan, N. Lipovetzky, S. Sardinia, N. van Beest, \u0026hellip; , \u0026ldquo;Process mining over sensor data: Goal recognition for powered transhumeral prostheses\u0026rdquo;, Information Systems, vol. 132, 102540, 2025.\nA. Mohammadi, C. Wang, T. Yu, Y. Tan, P. Choong, and D. Oetomo, \u0026ldquo;An information-rich and highly wearable soft sensor system based on displacement myography for practical hand gesture interfaces\u0026rdquo;, IEEE Journal of Biomedical and Health Informatics, vol. 29, no. 5, pp. 3451–3464, 2025.\nT. Yu, A. Mohammadi, Y. Tan, P. Choong, and D. Oetomo, \u0026ldquo;Discrete-Target Prosthesis Control Using Uncertainty-Aware Classification for Smooth and Efficient Gross Arm Movement\u0026rdquo;, IEEE Trans. on Neural Systems and Rehabilitation Engineering, vol. 32, pp. 3210–3221, 2024.\nT. Yu, A. Mohammadi, Y. Tan, P. Choong, and D. Oetomo, \u0026ldquo;Sensor selection with composite features in identifying user-intended poses for human-prosthetic interfaces\u0026rdquo;, IEEE Trans. on Neural Systems and Rehabilitation Engineering, vol. 31, pp. 1732–1742, 2023.\nR. Garcia-Rosas, T. Yu, D. Oetomo, C. Manzie, Y. Tan, and P. Choong, \u0026ldquo;Exploiting inherent human motor behaviour in the online personalisation of human-prosthetic interfaces\u0026rdquo;, IEEE Robotics and Automation Letters, vol. 6, no. 2, pp. 1973–1980, 2021.\nConference # Z. Su, T. Yu, N. Lipovetzky, A. Mohammadi, D. Oetomo, A. Polyvyanyy, \u0026hellip; , \u0026ldquo;Data-driven goal recognition in transhumeral prostheses using process mining techniques\u0026rdquo;, Proc. 2023 5th International Conference on Process Mining (ICPM), pp. 25–32, 2023.\nT. Yu, A. Mohammadi, Y. Tan, P. Choong, and D. Oetomo, \u0026ldquo;Feasibility evaluation of online classification-based control for gross movement in a 2-DoF prosthetic arm\u0026rdquo;, Proc. 2023 45th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), 2023.\nT. Yu, R. Garcia-Rosas, A. Mohammadi, Y. Tan, P. Choong, and D. Oetomo, \u0026ldquo;Separability of input features and the resulting accuracy in classifying target poses for active transhumeral prosthetic interfaces\u0026rdquo;, Proc. 2021 43rd Annual International Conference of the IEEE Engineering Engineering in Medicine and Biology Society (EMBC), 2021.\nT. Yu, R. Garcia-Rosas, A. Mohammadi, Y. Tan, P. Choong, and D. Oetomo, \u0026ldquo;Comparing the outcomes of population-averaged and personalised input feature selection for transhumeral prosthetic interfaces\u0026rdquo;, Proc. 2021 IEEE Int. Conf. on Systems, Man, and Cybernetics (SMC), 2021.\n","date":"17 February 2026","externalUrl":null,"permalink":"/publications/","section":"Welcome","summary":"","title":"Publications","type":"page"},{"content":"","date":"17 February 2026","externalUrl":null,"permalink":"/","section":"Welcome","summary":"","title":"Welcome","type":"page"},{"content":" Uncertainty-aware Prosthesis Control based on Bayesian Learning # Minimised undesired prosthesis movements caused by environmental uncertainties. Achieved a 30% reduction in task completion time compared with conventional methods (statistically significant).\nDeveloped the decision-making system involving biosignal processing (EMG and joint kinematics), motion control, and machine learning.\nBuilt a dedicated experimental platform using Unity (C#) for VR simulation and data logging at up to 2 kHz, ESP32 for embedded sensor data acquisition and transmission firmware, and Python for online decision-making.\nPublished in IEEE Transactions on Neural Systems and Rehabilitation Engineering (IEEE TNSRE). [Paper] [VR Code] [Dataset]\nReal-time Optimisation \u0026amp; Personalisation using Extremum Seeking Control # Enables real-time adjustment of controller parameters for optimal performance. Reduced compensatory movements of trunk and shoulder (statistically significant).\nImplemented Extremum Seeking Control and motion data acquisition firmware on SAMD21 and ESP32 microcontrollers using the Bosch BNO055 sensor on FreeRTOS and bare-metal platforms with DMA, I2C, SPI, ADC, and BLE communication interfaces.\nDesigned and manufactured the mechatronic prototype using 3D printing and laser cutting.\nCollaborated with colleagues at Human Robotics Lab. Published in IEEE Robotics and Automation Letter (IEEE RA-L). [Paper] [Dataset]\nProcess-mining-based Framework for Human Intention Detection # Developed a reasoning framework for human intention detection leveraging process-mining techniques and Petri nets.\nExample: A Petri net is extracted from EMG and motion data of a human subject reaching a single target, with actions \\(e_i\\) connected through state nodes (circles). The grey actions represent a specific type of movement event starting from the filled circle. Collaborated with colleagues at Process Science and Technology Research Group and Human Robotics Lab. Published in Information Systems and ICPM. [Paper] [Code] ","date":"10 August 2024","externalUrl":null,"permalink":"/projects/prosthesiscontrol_unimelb/","section":"Projects","summary":"Developed machine learning and control algorithms for human intention detection and prosthesis control with validation using VR and robotic prototypes.","title":"Data-driven Upper-limb Prosthesis Control and Validation","type":"projects"},{"content":"","date":"10 August 2024","externalUrl":null,"permalink":"/tags/emg/","section":"Tags","summary":"","title":"EMG","type":"tags"},{"content":"","date":"10 August 2024","externalUrl":null,"permalink":"/tags/intention-detection/","section":"Tags","summary":"","title":"Intention Detection","type":"tags"},{"content":"","date":"10 August 2024","externalUrl":null,"permalink":"/tags/machine-learning/","section":"Tags","summary":"","title":"Machine Learning","type":"tags"},{"content":"","date":"10 August 2024","externalUrl":null,"permalink":"/tags/motion/","section":"Tags","summary":"","title":"Motion","type":"tags"},{"content":"Project Portfolio\n","date":"10 August 2024","externalUrl":null,"permalink":"/projects/","section":"Projects","summary":"","title":"Projects","type":"projects"},{"content":"","date":"10 August 2024","externalUrl":null,"permalink":"/tags/samd21/","section":"Tags","summary":"","title":"SAMD21","type":"tags"},{"content":"","date":"10 August 2024","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"10 August 2024","externalUrl":null,"permalink":"/tags/vr-unity/","section":"Tags","summary":"","title":"VR (Unity)","type":"tags"},{"content":"","date":"1 August 2024","externalUrl":null,"permalink":"/tags/3d-printing/","section":"Tags","summary":"","title":"3D Printing","type":"tags"},{"content":"","date":"1 August 2024","externalUrl":null,"permalink":"/tags/esp32/","section":"Tags","summary":"","title":"ESP32","type":"tags"},{"content":"","date":"1 August 2024","externalUrl":null,"permalink":"/tags/hand-gesture/","section":"Tags","summary":"","title":"Hand Gesture","type":"tags"},{"content":" Wearable Soft Sensor System for Hand Gesture Recognition # This integrated sensor system comprises a 3D-printable soft sensor body and an embedded signal-processing and data-transmission module. It is highly wearable and achieves 97.7% accuracy for 13 hand gestures, making it suitable for virtual-reality interaction and prosthesis control.\nProgrammed the ESP32 microcontrollers: implemented sensor-data acquisition and transmission firmware using SPI, ADC, BLE, and Wi‑Fi, and developed a virtual-reality interaction environment in Unity (C#). Manufactured the sensor body by 3D printing using soft thermoplastic polyurethane (TPU) material.\nCollaborated with colleagues at Human Robotics Lab. Results were published in the IEEE Journal of Biomedical and Health Informatics (IEEE JBHI). [Paper]\n","date":"1 August 2024","externalUrl":null,"permalink":"/projects/hrisensor_unimelb/","section":"Projects","summary":"Develop novel wearable sensor systems enabling accurate human intention detection (e.g., hand gesture recognition), and allowing seamless interaction.","title":"Wearable Sensor Systems for Seamless Human-Machine Interaction","type":"projects"},{"content":" VR Platform for Studying Human–Autonomy Interaction # Developed a VR platform in Unreal Engine (C++) that simulates a human-operated vehicle interacting with autonomous vehicles. [Demo Code]\nDeveloped a multi-threaded sensor data acquisition and logging system with software interfaces for the VIVE Eye Tracker, Xsens motion-capture system, and a standalone Unreal plugin for Delsys EMG. [Plugin Code]\nData-driven Model for Human-State Prediction # Developed machine-learning models to predict human attention (gaze) and affective states (stress, trust, workload) using Transformer architectures in PyTorch, supporting human-centred adaptive VR training solutions for the mining and maritime industries. ","date":"1 July 2024","externalUrl":null,"permalink":"/projects/miningsimulator_unimelb/","section":"Projects","summary":"Developed human-state prediction models for VR training that supports effective human–autonomy collaboration.","title":"Data-driven Modelling for Human–Robot Interaction in the Mining and Maritime Industries","type":"projects"},{"content":"","date":"1 July 2024","externalUrl":null,"permalink":"/tags/eye-gaze/","section":"Tags","summary":"","title":"Eye Gaze","type":"tags"},{"content":"","date":"1 July 2024","externalUrl":null,"permalink":"/tags/transformer/","section":"Tags","summary":"","title":"Transformer","type":"tags"},{"content":"","date":"1 July 2024","externalUrl":null,"permalink":"/tags/vr-unreal/","section":"Tags","summary":"","title":"VR (Unreal)","type":"tags"},{"content":"","date":"1 July 2020","externalUrl":null,"permalink":"/tags/mechanical-design/","section":"Tags","summary":"","title":"Mechanical Design","type":"tags"},{"content":"","date":"1 July 2020","externalUrl":null,"permalink":"/tags/plc/","section":"Tags","summary":"","title":"PLC","type":"tags"},{"content":" Pneumatic Engine (Air Motor) Test Rig # Developed a pneumatic engine test rig at Zhejiang University with integrated torque, pressure, flow, and temperature sensors, along with Festo valves and actuators. The system underwent comprehensive calibration and performance validation.\nProgrammed STM32 bare metal firmware for sensor data acquisition and control at rates up to 50 kHz. Utilized peripherals include DMA, ADC, SPI, I2C, UART, and GPIO.\nDesigned and manufactured mechanical components including bearings, shafts, gears, and mounting parts using CAD and CNC machining, ensuring tolerance and fit.\nPneumatic-based Industrial Assembly Systems # Programmed industrial pneumatic assembly systems using Bosch Rexroth PLCs and Festo pneumatic components. Performed system debugging and optimisation to enhance operational efficiency.\nThis demonstration features the same teaching system; video credit: Ray Morris.\n","date":"1 July 2020","externalUrl":null,"permalink":"/projects/pneumatic_zju/","section":"Projects","summary":"Developed pneumatic-based mechatronic systems, including a pneumatic engine test rig and industrial assembly system.","title":"Pneumatic-based Automation System","type":"projects"},{"content":"","date":"1 July 2020","externalUrl":null,"permalink":"/tags/stm32/","section":"Tags","summary":"","title":"STM32","type":"tags"},{"content":"","date":"10 August 2018","externalUrl":null,"permalink":"/tags/mechatronics/","section":"Tags","summary":"","title":"Mechatronics","type":"tags"},{"content":" Serial Manipulator Robotic System # I served as Head Tutor for MCEN90028 Robotics Systems at the University of Melbourne from 2020 to 2024. I received First-Class Honours (H1) as a student in 2019. Subject content included robot kinematics (DH parameters), differential kinematics (Jacobian), dynamics, and closed-loop control systems.\nI delivered technical material to students at a range of levels and mentored postgraduate students on robot prototyping projects, including mechanical design, component selection, embedded system design, and programming.\nHands-on Robotic Prototyping Robotic System Modelling and Simulation 2020–2025 Capstone Project (Supervisor / Mentor) # I served as a Capstone project supervisor and mentor at the University of Melbourne from 2020 to 2025. Two teams I supervised received Merit Awards for their projects in the Endeavour Exhibition.\n","date":"10 August 2018","externalUrl":null,"permalink":"/projects/roboticssubject_unimelb/","section":"Projects","summary":"Tutor and mentor in Robotics subjects, teaching robot kinematics, dynamics, control systems, and hands-on design \u0026 prototyping.","title":"Mechatronics \u0026 Robotics Engineering Teaching \u0026 Mentorship","type":"projects"},{"content":"","date":"10 August 2018","externalUrl":null,"permalink":"/tags/prototyping/","section":"Tags","summary":"","title":"Prototyping","type":"tags"},{"content":"","date":"10 August 2018","externalUrl":null,"permalink":"/tags/simulation/","section":"Tags","summary":"","title":"Simulation","type":"tags"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"}]